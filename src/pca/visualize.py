import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

df = pd.read_csv("E:/datasets/Red Wine Quality/winequality-red.csv")

# drop target variable
df.drop(columns=["quality"], inplace=True)

# standarize independent variables
for col in df.columns:
   df[col] = (df[col] - df[col].mean()) / df[col].std()

print(df.head())
X_train = df.to_numpy()

# eigenvlaues and vector from main.cpp
eigenvalues = [0.0569278,
               0.17818,
               0.347412,
               0.407809,
               0.583837,
               0.647386,
               0.943037,
               1.13958,
               1.57658,
               2.0153,
               3.01845]

eigenvectors = [
   [  -0.643889,  0.246925,   0.177541,   0.171457,  -0.352272, -0.0910322,  0.0700278,  -0.238224,   0.101754, -0.0954194,   0.500021],
   [  0.0122777, -0.376759,  -0.107049,  0.0863281,   -0.51438,  -0.414071,  -0.221484,  0.0304599,   0.495552,   0.222832,   -0.24029],
   [  0.0855734, -0.644477,  -0.336681,   0.386253,   0.096669, -0.0378795,  0.0554674, -0.0734813,  -0.258094,  -0.112352,   0.465069],
   [  -0.184544,-0.0859452,  0.0078317,  -0.296961,   0.311244, -0.0607222,  -0.712405,  -0.318708,  -0.118637,    0.35171,   0.151259],
   [ -0.0529266,  0.210156,   0.111385,   0.396641,   0.348279,   -0.28827,  -0.230056,   0.676891,   0.136981,   0.108631,   0.192957],
   [  0.0455655, -0.222956,   0.645337,   0.174655,   -0.14592,  0.0395795,   0.193633,   0.023003,  -0.367579,   0.550022, -0.0522417],
   [-0.0586656,   0.337991,  -0.617208,  0.0153273,  -0.104646,  -0.132226,    0.25268,   0.018691,  -0.245506,   0.590035, 0.00971622],
   [  0.558269,   0.243846,  0.0255141,   0.205665,  -0.170543,   0.425082,  -0.165589,  -0.161524,   0.348369,   0.216697,   0.392832],
   [ -0.345125, -0.0113566,  -0.160312,   0.516069, -0.0601788,   0.551728,  -0.283971, 0.00931289, -0.0694511, 0.00374902,  -0.441751],
   [-0.0650878,  -0.122385, -0.0782569,  -0.422691,  -0.451875,   0.319756,  -0.210326,   0.578525,  -0.232951, -0.0447544,   0.233157],
   [  0.317089,   0.302758,  0.0362794,   0.224535,  -0.338616,  -0.354464,  -0.358999,  -0.124174,  -0.518445,  -0.305741, -0.0958783]]


eigenvalues = np.array(eigenvalues)
eigenvectors = np.array(eigenvectors)

var = np.sum(eigenvalues)
pc1_var = eigenvalues[-1]/var
pc2_var = eigenvalues[-2]/var

pc1 = eigenvectors[-1, :]
pc2 = eigenvectors[-2, :]

pc1 = np.dot(X_train, pc1.T)
pc2 = np.dot(X_train, pc2.T)

# plot PC1 and PC2
plt.figure(figsize=(8,6))
plt.scatter(pc1, pc2, alpha=0.3)
plt.title("PCA")
plt.xlabel(f'PC1  ({int(pc1_var*100)})%')
plt.ylabel(f'PC2  ({int(pc2_var*100)})%')
plt.show()